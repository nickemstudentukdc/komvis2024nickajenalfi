{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP5EvQYBkhPI",
        "outputId": "10ef8ebf-a94a-424b-d1b5-97fbde1602bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jessicali9530/celeba-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.33G/1.33G [00:17<00:00, 83.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "# Download the CelebA dataset using kagglehub\n",
        "jessicali9530_celeba_dataset_path = kagglehub.dataset_download('jessicali9530/celeba-dataset')\n",
        "print('Data source import complete.')\n",
        "\n",
        "# Importing scikit-learn tools for splitting and evaluating the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Importing TensorFlow and Keras tools\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, GlobalAveragePooling2D\n",
        "\n",
        "# Print confirmation\n",
        "print('Libraries imported successfully.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASIC_PATH = \"/kaggle/input/celeba-dataset\"\n",
        "IMG_PATH = os.path.join(BASIC_PATH,'img_align_celeba/img_align_celeba')\n",
        "FEATURE_PATH = os.path.join(BASIC_PATH,'list_attr_celeba.csv')"
      ],
      "metadata": {
        "id": "5iJ5nzeXlT8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASIC_PATH = jessicali9530_celeba_dataset_path\n",
        "IMG_PATH = os.path.join(BASIC_PATH,'img_align_celeba/img_align_celeba')\n",
        "FEATURE_PATH = os.path.join(BASIC_PATH,'list_attr_celeba.csv')\n"
      ],
      "metadata": {
        "id": "bloiScGWlYpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LIST_ATTR_PATH = os.path.join(BASIC_PATH,'list_attr_celeba.csv')\n",
        "DF_ATTR = pd.read_csv(BASIC_PATH + '/list_attr_celeba.csv', delimiter=',')\n",
        "print(IMG_PATH, LIST_ATTR_PATH)\n",
        "DF_ATTR.head()"
      ],
      "metadata": {
        "id": "zkB0G5oYkzd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DF_PARTITION = pd.read_csv(BASIC_PATH + '/list_eval_partition.csv')"
      ],
      "metadata": {
        "id": "OUTrbWmKk3pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DF_ATTR.set_index('image_id', inplace=True)\n",
        "DF_ATTR.replace(to_replace=-1, value=0, inplace=True)\n",
        "DF_ATTR.shape"
      ],
      "metadata": {
        "id": "1ttmGecBk6Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DF_PARTITION['partition'].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "cfbzl1kfk8mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: hitung dan tampilkan jumlah total dataset diatas\n",
        "\n",
        "total_dataset = DF_ATTR.shape[0]\n",
        "print(f\"Total dataset: {total_dataset}\")"
      ],
      "metadata": {
        "id": "IHKH0Z-EoIQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengecek File Duplikat, Menghitung Jumlahnya dan Menampilkan 5 File Contoh\n",
        "import hashlib\n",
        "# Library yang digunakan : os dan hashlib\n",
        "\n",
        "# Mencari semua file dengan ekstensi gambar dalam folder\n",
        "image_files = [file for file in os.listdir(IMG_PATH) if file.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Menggunakan dictionary untuk menyimpan hash nilai dan daftar file dengan hash yang sama\n",
        "duplicate_files = {}\n",
        "\n",
        "# Memeriksa setiap file gambar\n",
        "for file_name in image_files:\n",
        "    file_path = os.path.join(IMG_PATH, file_name)\n",
        "    with open(file_path, 'rb') as f:\n",
        "        file_hash = hashlib.md5(f.read()).hexdigest()\n",
        "\n",
        "    if file_hash not in duplicate_files:\n",
        "        duplicate_files[file_hash] = [file_name]\n",
        "    else:\n",
        "        duplicate_files[file_hash].append(file_name)\n",
        "\n",
        "# Menghitung total file yang duplikat\n",
        "total_duplicate_files = sum(len(files) - 1 for files in duplicate_files.values())\n",
        "\n",
        "# Menampilkan 8 contoh nama file yang duplikat\n",
        "print(\"Contoh file duplikat:\")\n",
        "count = 0\n",
        "for file_list in duplicate_files.values():\n",
        "    if len(file_list) > 1:\n",
        "        for file_name in file_list[:8]:\n",
        "            count += 1\n",
        "            print(file_name)\n",
        "            if count == 8:\n",
        "                break\n",
        "    if count == 8:\n",
        "        break\n",
        "\n",
        "# Menampilkan total file yang duplikat\n",
        "print(f\"Total file duplikat: {total_duplicate_files}\")\n",
        "\n",
        "# Mengumpulkan 8 contoh file duplikat\n",
        "duplicate_examples = []\n",
        "for file_list in duplicate_files.values():\n",
        "    if len(file_list) > 1:\n",
        "        duplicate_examples.extend(file_list[:8])\n",
        "    if len(duplicate_examples) >= 10:\n",
        "        break\n",
        "\n",
        "# Menampilkan 8 foto duplikat dengan judul sebagai nama file\n",
        "fig, axes = plt.subplots(2, 4, figsize=(10, 6))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    if i < len(duplicate_examples):\n",
        "        file_name = duplicate_examples[i]\n",
        "        file_path = os.path.join(IMG_PATH, file_name)\n",
        "        image = plt.imread(file_path)\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(file_name)\n",
        "        plt.suptitle('Contoh Foto Duplikat')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Code Modif dari Chat GPT"
      ],
      "metadata": {
        "id": "oBHQN8q3oPz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat List Nama File Foto untuk Join dengan Nama File pada File list_attribute.csv\n",
        "import glob\n",
        "# Library yang digunakan : glob dan pandas\n",
        "\n",
        "# Tentukan pola nama file foto (misal: JPEG, PNG)\n",
        "file_ekstensi = '*.jpg' # Ganti dengan ekstensi file gambar yang sesuai\n",
        "\n",
        "# Tentukan direktori tempat file-file gambar berada\n",
        "direktori_foto = IMG_PATH\n",
        "\n",
        "# Mendapatkan list nama file\n",
        "nama_file = glob.glob(direktori_foto + '/' + file_ekstensi)\n",
        "\n",
        "# List nama file dijadikan dataframe\n",
        "data = pd.DataFrame(nama_file, columns = ['image_id'])\n",
        "\n",
        "# Menampilkan dataframe\n",
        "data.head()\n",
        "\n",
        "# Code Modif dari Chat GPT"
      ],
      "metadata": {
        "id": "LgVWwwVlov6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuang karakter pertama hingga sebelum nama file\n",
        "data['image_id'] = data['image_id'].str.split('\\\\').str[-1]\n",
        "data.head()\n",
        "# Note: menggunakan '\\\\' karena pemisah antar folder adalah '\\'\n",
        "\n",
        "# Code Modif dari Googling"
      ],
      "metadata": {
        "id": "Nx2km9fxpPE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset 'list_attribute.csv' tampilkan juga nama file\n",
        "\n",
        "print(f\"File yang digunakan: {LIST_ATTR_PATH}\")\n",
        "df_attr = pd.read_csv(LIST_ATTR_PATH)\n",
        "df_attr.head()"
      ],
      "metadata": {
        "id": "4J9oi1WSpY7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Cek Informasi pada DataFrame\n",
        "\n",
        "# Cek Informasi pada DataFrame DF_ATTR\n",
        "print(\"Informasi DataFrame DF_ATTR:\")\n",
        "print(DF_ATTR.info())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Cek Informasi pada DataFrame DF_PARTITION\n",
        "print(\"Informasi DataFrame DF_PARTITION:\")\n",
        "print(DF_PARTITION.info())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Deskripsi statistik DF_ATTR\n",
        "print(\"Deskripsi Statistik DF_ATTR:\")\n",
        "print(DF_ATTR.describe())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Melihat jumlah data missing per kolom\n",
        "print(\"Jumlah Data Missing per Kolom DF_ATTR:\")\n",
        "print(DF_ATTR.isnull().sum())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Melihat jumlah data missing per kolom\n",
        "print(\"Jumlah Data Missing per Kolom DF_PARTITION:\")\n",
        "print(DF_PARTITION.isnull().sum())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Melihat korelasi antar kolom pada DF_ATTR\n",
        "print(\"Korelasi Antar Kolom DF_ATTR:\")\n",
        "print(DF_ATTR.corr())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Melihat nilai unik pada kolom 'partition' di DF_PARTITION\n",
        "print(\"Nilai Unik pada Kolom 'partition' di DF_PARTITION:\")\n",
        "print(DF_PARTITION['partition'].unique())\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "dODFCzLjpuPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Inner Join antara Objek 'data' dengan Objek 'list_attribute'\n",
        "\n",
        "# Inner Join antara Objek 'data' dengan Objek 'list_attribute'\n",
        "\n",
        "# Gabungkan 'data' dan 'DF_ATTR' berdasarkan 'image_id'\n",
        "merged_data = pd.merge(data, DF_ATTR, left_on='image_id', right_index=True, how='inner')\n",
        "\n",
        "# Tampilkan hasil penggabungan\n",
        "print(\"Hasil Inner Join:\")\n",
        "merged_data.head()"
      ],
      "metadata": {
        "id": "5EGVpXQlp1N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Cek Jumlah Baris dan kolom yang telah Join Inner\n",
        "\n",
        "# Cek jumlah baris dan kolom setelah inner join\n",
        "print(\"Jumlah baris dan kolom setelah inner join:\")\n",
        "print(merged_data.shape)"
      ],
      "metadata": {
        "id": "bplGBM2yp9Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # join the partition with the attributes\n",
        "\n",
        "# Gabungkan 'merged_data' dan 'DF_PARTITION' berdasarkan 'image_id'\n",
        "final_data = pd.merge(merged_data, DF_PARTITION, left_on='image_id', right_on='image_id', how='inner')\n",
        "\n",
        "# Tampilkan hasil penggabungan\n",
        "print(\"Hasil Inner Join antara merged_data dan DF_PARTITION:\")\n",
        "final_data.head()\n",
        "\n",
        "# Cek jumlah baris dan kolom setelah inner join\n",
        "print(\"Jumlah baris dan kolom setelah inner join:\")\n",
        "print(final_data.shape)\n",
        "DF_PARTITION.head()"
      ],
      "metadata": {
        "id": "3NvWH2XDsTlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the attributes csv files in a dataframe format.\n",
        "df = pd.read_csv(FEATURE_PATH, usecols=['image_id','Male'])\n",
        "df = df.sample(n=22000, random_state = 42).reset_index(drop=True)\n",
        "\n",
        "# Reset the columns values to categorical./\n",
        "df.loc[df['Male'] == -1,'Male'] = \"Female\"\n",
        "df.loc[df['Male'] == 1,'Male'] = \"Male\"\n",
        "\n",
        "# Change column names.\n",
        "df.columns = [\"image_id\", \"Gender\"]\n",
        "\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "LRPp3Lm6saNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Multiple Sample Images.\n",
        "for i in range(0, 6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "\n",
        "    # Display Multiple Sample Images.\n",
        "    img = cv2.imread(IMG_PATH + '/' + df[\"image_id\"][i])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display Image.\n",
        "    plt.imshow(img)\n",
        "    plt.title(img.shape)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C18ePRKLs1F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Get the category distribution.\n",
        "\n",
        "# Get the category distribution.\n",
        "gender_distribution = df['Gender'].value_counts()\n",
        "print(gender_distribution)\n",
        "\n",
        "# Visualize the category distribution (optional).\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(gender_distribution.index, gender_distribution.values)\n",
        "plt.title('Gender Distribution in the Dataset')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7uqgXzQgtPaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: buat distribution gender menjadi seimbang berdasarkan code diatas\n",
        "\n",
        "# Get the category distribution.\n",
        "gender_distribution = df['Gender'].value_counts()\n",
        "print(gender_distribution)\n",
        "\n",
        "# Calculate the minimum number of samples for each class\n",
        "min_samples = min(gender_distribution)\n",
        "\n",
        "# Create balanced datasets for each class\n",
        "balanced_df = pd.DataFrame()\n",
        "for gender in gender_distribution.index:\n",
        "  temp_df = df[df['Gender'] == gender].sample(n=min_samples, random_state=42)\n",
        "  balanced_df = pd.concat([balanced_df, temp_df])\n",
        "\n",
        "# Reset the index of the balanced dataframe\n",
        "balanced_df = balanced_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Get the new category distribution.\n",
        "new_gender_distribution = balanced_df['Gender'].value_counts()\n",
        "print(new_gender_distribution)\n",
        "\n",
        "# Visualize the new category distribution (optional).\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(new_gender_distribution.index, new_gender_distribution.values)\n",
        "plt.title('Gender Distribution in the Balanced Dataset')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "df = balanced_df"
      ],
      "metadata": {
        "id": "Kw-bc6e6tW7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Gender\"].value_counts().plot.bar()"
      ],
      "metadata": {
        "id": "apSWc61VtySO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.3)\n",
        "test_df, validation_df = train_test_split(test_df, test_size=0.33)"
      ],
      "metadata": {
        "id": "SF8IX4pXt0NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Train Sample Images : \", len(train_df))\n",
        "print(\"Total Test Sample Images : \", len(test_df))\n",
        "print(\"Total Validation Sample Images : \", len(validation_df))"
      ],
      "metadata": {
        "id": "N1WycKDSuDKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Define image size and batch size\n",
        "IMAGE_SIZE = (224, 224)  # VGG16 input size\n",
        "BATCH_SIZE = 32  # Set your batch size\n",
        "\n",
        "# Load VGG16 preprocessing function\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# Generate Train Images Data Generator with VGG16 preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    preprocessing_function=preprocess_input  # Use VGG16 preprocessing\n",
        ")\n",
        "\n",
        "# Create the train generator\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    IMG_PATH + \"/\",\n",
        "    x_col='image_id',\n",
        "    y_col='Gender',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='binary',\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n"
      ],
      "metadata": {
        "id": "TKsCGzZ9uFLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Generate Validation Images Data Generator with VGG16 preprocessing\n",
        "\n",
        "# Generate Validation Images Data Generator with VGG16 preprocessing\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Create the validation generator\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validation_df,\n",
        "    IMG_PATH + \"/\",\n",
        "    x_col='image_id',\n",
        "    y_col='Gender',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='binary',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "vZ9u69vIucu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Test Images Data Generator with VGG16 preprocessing\n",
        "test_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input  # Use VGG16 preprocessing\n",
        ")\n",
        "\n",
        "# Create the test generator\n",
        "test_generator = test_gen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    IMG_PATH + \"/\",\n",
        "    x_col='image_id',\n",
        "    y_col=None,  # No labels for test data\n",
        "    class_mode=None,  # No class mode for test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False  # Set to False for test data to maintain order\n",
        ")"
      ],
      "metadata": {
        "id": "CtaZeIFRulNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the VGG16 base model\n",
        "base_vgg16_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=IMAGE_SIZE + (3,))\n",
        "\n",
        "# Unfreeze the last 5 layers\n",
        "for layer in base_vgg16_model.layers[-5:]:\n",
        "    layer.trainable = True  # Set trainable to True for the last 5 layers\n",
        "\n",
        "# Optionally, freeze the rest of the layers if you want to fine-tune the model\n",
        "for layer in base_vgg16_model.layers[:-5]:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "52CsEmhYuv2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create the VGG16 model architecture\n",
        "vgg16_model = Sequential(\n",
        "    [\n",
        "        base_vgg16_model,  # Use the VGG16 base model\n",
        "        GlobalAveragePooling2D(),  # Pooling layer\n",
        "        BatchNormalization(),  # Normalization layer\n",
        "        Dense(256, activation='relu'),  # Fully connected layer with ReLU activation\n",
        "        BatchNormalization(),  # Another normalization layer\n",
        "        Dense(2, activation='softmax')  # Output layer for binary classification\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Alternatively, if you want to use predictions separately (not necessary in this case)\n",
        "# x = base_vgg16_model.output\n",
        "# predictions = Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "# Compile the VGG16 model\n",
        "base_learning_rate = 0.00001\n",
        "vgg16_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # Loss function for multi-class classification\n",
        "    metrics=['accuracy']  # Metric for evaluation\n",
        ")\n"
      ],
      "metadata": {
        "id": "k70BNb1yvD23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "earlystop = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=10,         # Stop training after 10 epochs with no improvement\n",
        "    restore_best_weights=True  # Restore weights of the best epoch\n",
        ")\n",
        "\n",
        "# Learning rate reduction when a plateau is detected\n",
        "learning_rate_reduction = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',  # Monitor validation accuracy for reducing the learning rate\n",
        "    patience=4,              # Wait for 4 epochs with no improvement\n",
        "    verbose=1,               # Print a message when learning rate is reduced\n",
        "    factor=0.5,              # Reduce learning rate by half\n",
        "    min_lr=0.0001            # Minimum learning rate to reach\n",
        ")\n",
        "\n",
        "# Combine callbacks\n",
        "callbacks = [earlystop, learning_rate_reduction]\n"
      ],
      "metadata": {
        "id": "z-HUggFKvNmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Train the VGG16 model\n",
        "\n",
        "# Train the VGG16 model\n",
        "epochs = 10  # Adjust the number of training epochs as needed\n",
        "\n",
        "history = vgg16_model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "5mXXpJ7ivVY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}